{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca2c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "HEADERS = {\"accept\": \"application/json\"}\n",
    "\n",
    "# ì—°ê²° í’€ì„ ì¬ì‚¬ìš©í•˜ëŠ” ì„¸ì…˜ ìƒì„±\n",
    "def create_session():\n",
    "    \"\"\"ì¬ì‹œë„ ë¡œì§ê³¼ ì—°ê²° í’€ì´ ìˆëŠ” ì„¸ì…˜ ìƒì„±\"\"\"\n",
    "    session = requests.Session()\n",
    "    retry = Retry(\n",
    "        total=3,\n",
    "        backoff_factor=0.3,\n",
    "        status_forcelist=[500, 502, 503, 504]\n",
    "    )\n",
    "    adapter = HTTPAdapter(\n",
    "        max_retries=retry,\n",
    "        pool_connections=50,\n",
    "        pool_maxsize=50\n",
    "    )\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    return session\n",
    "\n",
    "# ì „ì—­ ì„¸ì…˜\n",
    "session = create_session()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# í—¬í¼ í•¨ìˆ˜\n",
    "# ----------------------------------------------------------\n",
    "def simple_list_to_str(lst, key=\"name\"):\n",
    "    return \", \".join([item.get(key, \"\") for item in lst]) if lst else \"\"\n",
    "\n",
    "\n",
    "def generate_date_periods(start_date, end_date, months=3):\n",
    "    \"\"\"\n",
    "    ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ ì‚¬ì´ë¥¼ Nê°œì›” ë‹¨ìœ„ë¡œ ë¶„í•  (ì •í™•í•œ ë‹¬ ê³„ì‚°)\n",
    "    \"\"\"\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    \n",
    "    periods = []\n",
    "    current = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    \n",
    "    while current <= end_dt:\n",
    "        # ë‹¤ìŒ ê¸°ê°„ì˜ ì‹œì‘ì¼ ê³„ì‚° (ì •í™•íˆ Nê°œì›” í›„)\n",
    "        next_date = current + relativedelta(months=months)\n",
    "        period_end = min(next_date - timedelta(days=1), end_dt)\n",
    "        \n",
    "        periods.append((\n",
    "            current.strftime(\"%Y-%m-%d\"),\n",
    "            period_end.strftime(\"%Y-%m-%d\")\n",
    "        ))\n",
    "        \n",
    "        current = next_date\n",
    "    \n",
    "    return periods\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1) ì§€ì •ëœ ê¸°ê°„ ë™ì•ˆ ë°©ì˜ëœ TV Series ì „ì²´ ìˆ˜ì§‘ (ë©€í‹°ìŠ¤ë ˆë“œ)\n",
    "# ----------------------------------------------------------\n",
    "def fetch_single_page(page, start_date, end_date):\n",
    "    \"\"\"ë‹¨ì¼ í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    base_url = \"https://api.themoviedb.org/3/discover/tv\"\n",
    "    params = {\n",
    "        \"api_key\": API_KEY,\n",
    "        \"language\": \"en-US\",\n",
    "        \"sort_by\": \"popularity.desc\",\n",
    "        \"first_air_date.gte\": start_date,\n",
    "        \"first_air_date.lte\": end_date,\n",
    "        \"page\": page,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = session.get(base_url, params=params, headers=HEADERS, timeout=10)\n",
    "        data = response.json()\n",
    "        return data.get(\"results\", []), data.get(\"total_pages\", 1), data.get(\"total_results\", 0)\n",
    "    except Exception as e:\n",
    "        print(f\"í˜ì´ì§€ {page}ì—ì„œ ì˜¤ë¥˜: {e}\")\n",
    "        return [], 1, 0\n",
    "\n",
    "\n",
    "def fetch_tv_series_between_dates(start_date, end_date):\n",
    "    \"\"\"\n",
    "    TMDB Discover APIë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ê¸°ê°„ ë‚´ ëª¨ë“  TV Series ëª©ë¡ì„ ìˆ˜ì§‘ (ë©€í‹°ìŠ¤ë ˆë“œ).\n",
    "    ìµœëŒ€ 500í˜ì´ì§€(10,000ê°œ) ì œí•œ ì ìš©\n",
    "    \"\"\"\n",
    "    # ë¨¼ì € ì²« í˜ì´ì§€ë¥¼ ê°€ì ¸ì™€ì„œ ì´ í˜ì´ì§€ ìˆ˜ í™•ì¸\n",
    "    results, total_pages, total_results = fetch_single_page(1, start_date, end_date)\n",
    "    all_series = results\n",
    "    \n",
    "    # 500í˜ì´ì§€ ì œí•œ ì ìš©\n",
    "    max_pages = min(total_pages, 500)\n",
    "    \n",
    "    print(f\"  ğŸ“Š ì´ {total_results:,}ê°œ ({total_pages}í˜ì´ì§€) â†’ ìˆ˜ì§‘ ê°€ëŠ¥: {max_pages}í˜ì´ì§€\")\n",
    "    \n",
    "    if total_pages > 500:\n",
    "        print(f\"  âš ï¸  500í˜ì´ì§€ ì œí•œìœ¼ë¡œ ì¸í•´ {(total_pages - 500) * 20:,}ê°œëŠ” ìˆ˜ì§‘ ë¶ˆê°€\")\n",
    "    \n",
    "    if max_pages == 1:\n",
    "        return all_series\n",
    "    \n",
    "    # ë‚˜ë¨¸ì§€ í˜ì´ì§€ë¥¼ ë©€í‹°ìŠ¤ë ˆë“œë¡œ ìˆ˜ì§‘\n",
    "    with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "        futures = {\n",
    "            executor.submit(fetch_single_page, page, start_date, end_date): page \n",
    "            for page in range(2, max_pages + 1)\n",
    "        }\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=f\"  í˜ì´ì§€ ìˆ˜ì§‘\", leave=False):\n",
    "            page_results, _, _ = future.result()\n",
    "            all_series.extend(page_results)\n",
    "    \n",
    "    return all_series\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2) ë¦¬ë·° ìˆ˜ì§‘ (ëª¨ë“  í˜ì´ì§€)\n",
    "# ----------------------------------------------------------\n",
    "def fetch_reviews(content_type, content_id):\n",
    "    \"\"\"\n",
    "    ëª¨ë“  ë¦¬ë·°ë¥¼ ìˆ˜ì§‘ (í˜ì´ì§€ë„¤ì´ì…˜ ì²˜ë¦¬)\n",
    "    \"\"\"\n",
    "    url = f\"https://api.themoviedb.org/3/{content_type}/{content_id}/reviews\"\n",
    "    all_reviews = []\n",
    "    page = 1\n",
    "    \n",
    "    while True:\n",
    "        params = {\"api_key\": API_KEY, \"language\": \"en-US\", \"page\": page}\n",
    "        \n",
    "        try:\n",
    "            response = session.get(url, params=params, headers=HEADERS, timeout=10)\n",
    "            if response.status_code != 200:\n",
    "                break\n",
    "            \n",
    "            data = response.json()\n",
    "            reviews = data.get(\"results\", [])\n",
    "            \n",
    "            if not reviews:\n",
    "                break\n",
    "            \n",
    "            for review in reviews:\n",
    "                author = review.get(\"author\", \"unknown\")\n",
    "                rating = review.get(\"author_details\", {}).get(\"rating\")\n",
    "                rating_str = f\" (Rating: {rating})\" if rating else \"\"\n",
    "                content = review.get(\"content\", \"\").replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "                all_reviews.append(f\"{author}{rating_str}: {content}\")\n",
    "            \n",
    "            # ë‹¤ìŒ í˜ì´ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸\n",
    "            total_pages = data.get(\"total_pages\", 1)\n",
    "            if page >= total_pages:\n",
    "                break\n",
    "            \n",
    "            page += 1\n",
    "            \n",
    "        except:\n",
    "            break\n",
    "    \n",
    "    return \" || \".join(all_reviews) if all_reviews else \"\"\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3) TV Series ìƒì„¸ ì •ë³´ ìˆ˜ì§‘\n",
    "# ----------------------------------------------------------\n",
    "def fetch_tv_details(series_id):\n",
    "    url = f\"https://api.themoviedb.org/3/tv/{series_id}\"\n",
    "    params = {\"api_key\": API_KEY, \"language\": \"en-US\", \"append_to_response\": \"credits\"}\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, params=params, headers=HEADERS, timeout=10)\n",
    "        data = response.json()\n",
    "\n",
    "        # last_episode_to_air ë¶„ë¦¬\n",
    "        last_ep = data.get(\"last_episode_to_air\", {}) or {}\n",
    "\n",
    "        record = {\n",
    "            \"id\": data.get(\"id\"),\n",
    "            \"type\": \"tv_series\",\n",
    "            \"adult\": data.get(\"adult\"),\n",
    "            \"backdrop_path\": data.get(\"backdrop_path\"),\n",
    "            \"created_by\": simple_list_to_str(data.get(\"created_by\", [])),\n",
    "            \"episode_run_time\": \", \".join(map(str, data.get(\"episode_run_time\", []))) if data.get(\"episode_run_time\") else \"\",\n",
    "            \"first_air_date\": data.get(\"first_air_date\"),\n",
    "            \"genres\": simple_list_to_str(data.get(\"genres\", [])),\n",
    "            \"homepage\": data.get(\"homepage\"),\n",
    "            \"in_production\": data.get(\"in_production\"),\n",
    "            \"languages\": \", \".join(data.get(\"languages\", [])),\n",
    "            \"last_air_date\": data.get(\"last_air_date\"),\n",
    "\n",
    "            # last_episode_to_airë¥¼ ê°œë³„ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„ë¦¬\n",
    "            \"last_episode_to_air_id\": last_ep.get(\"id\"),\n",
    "            \"last_episode_to_air_name\": last_ep.get(\"name\"),\n",
    "            \"last_episode_to_air_overview\": last_ep.get(\"overview\"),\n",
    "            \"last_episode_to_air_vote_average\": last_ep.get(\"vote_average\"),\n",
    "            \"last_episode_to_air_vote_count\": last_ep.get(\"vote_count\"),\n",
    "            \"last_episode_to_air_air_date\": last_ep.get(\"air_date\"),\n",
    "            \"last_episode_to_air_episode_number\": last_ep.get(\"episode_number\"),\n",
    "            \"last_episode_to_air_production_code\": last_ep.get(\"production_code\"),\n",
    "            \"last_episode_to_air_runtime\": last_ep.get(\"runtime\"),\n",
    "            \"last_episode_to_air_season_number\": last_ep.get(\"season_number\"),\n",
    "            \"last_episode_to_air_show_id\": last_ep.get(\"show_id\"),\n",
    "            \"last_episode_to_air_still_path\": last_ep.get(\"still_path\"),\n",
    "\n",
    "            \"name\": data.get(\"name\"),\n",
    "            \"next_episode_to_air\": None,\n",
    "            \"networks\": simple_list_to_str(data.get(\"networks\", [])),\n",
    "            \"number_of_episodes\": data.get(\"number_of_episodes\"),\n",
    "            \"number_of_seasons\": data.get(\"number_of_seasons\"),\n",
    "            \"origin_country\": \", \".join(data.get(\"origin_country\", [])),\n",
    "            \"original_language\": data.get(\"original_language\"),\n",
    "            \"original_name\": data.get(\"original_name\"),\n",
    "            \"overview\": data.get(\"overview\"),\n",
    "            \"popularity\": data.get(\"popularity\"),\n",
    "            \"poster_path\": data.get(\"poster_path\"),\n",
    "            \"production_companies\": simple_list_to_str(data.get(\"production_companies\", [])),\n",
    "            \"production_countries\": simple_list_to_str(data.get(\"production_countries\", [])),\n",
    "            \"seasons\": \"; \".join(\n",
    "                f\"{s.get('season_number')}: {s.get('name')} ({s.get('episode_count')} eps)\"\n",
    "                for s in data.get(\"seasons\", [])\n",
    "            ),\n",
    "            \"spoken_languages\": simple_list_to_str(data.get(\"spoken_languages\", [])),\n",
    "            \"status\": data.get(\"status\"),\n",
    "            \"tagline\": data.get(\"tagline\"),\n",
    "            \"type_detail\": data.get(\"type\"),\n",
    "            \"vote_average\": data.get(\"vote_average\"),\n",
    "            \"vote_count\": data.get(\"vote_count\"),\n",
    "        }\n",
    "\n",
    "        record[\"review\"] = fetch_reviews(\"tv\", series_id)\n",
    "\n",
    "        return record\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching details for {series_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4) MAIN ì‹¤í–‰ë¶€\n",
    "# ----------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 90)\n",
    "    print(\"ğŸš€ PERIOD-SPLIT MULTITHREAD VERSION â€” TV SERIES (2023.01.01 ~ 2025.06.30)\")\n",
    "    print(\"=\" * 90)\n",
    "\n",
    "    start_date = \"2023-01-01\"\n",
    "    end_date = \"2025-06-30\"\n",
    "\n",
    "    total_start = time.time()\n",
    "\n",
    "    # ê¸°ê°„ì„ 3ê°œì›” ë‹¨ìœ„ë¡œ ë¶„í• \n",
    "    periods = generate_date_periods(start_date, end_date, months=3)\n",
    "    \n",
    "    print(f\"\\nğŸ“… ì „ì²´ ê¸°ê°„: {start_date} ~ {end_date}\")\n",
    "    print(f\"ğŸ“Š ë¶„í•  ê¸°ê°„: {len(periods)}ê°œ (ê° 3ê°œì›”ì”©)\")\n",
    "    print(\"=\"*90)\n",
    "\n",
    "    all_tv_series = []\n",
    "\n",
    "    # ê° ê¸°ê°„ë³„ë¡œ ë°ì´í„° ìˆ˜ì§‘\n",
    "    for idx, (period_start, period_end) in enumerate(periods, 1):\n",
    "        print(f\"\\n[{idx}/{len(periods)}] ğŸ“Œ ê¸°ê°„: {period_start} ~ {period_end}\")\n",
    "        \n",
    "        tv_series = fetch_tv_series_between_dates(period_start, period_end)\n",
    "        all_tv_series.extend(tv_series)\n",
    "        \n",
    "        print(f\"  âœ… ì´ ê¸°ê°„ ìˆ˜ì§‘: {len(tv_series):,}ê°œ (ëˆ„ì : {len(all_tv_series):,}ê°œ)\")\n",
    "\n",
    "    if not all_tv_series:\n",
    "        print(\"\\nâš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„° ì—†ìŒ. ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        exit()\n",
    "\n",
    "    # ì¤‘ë³µ ì œê±°\n",
    "    print(f\"\\n{'='*90}\")\n",
    "    print(f\"ğŸ§¹ ì¤‘ë³µ ì œê±° ì¤‘...\")\n",
    "    unique_series = {s[\"id\"]: s for s in all_tv_series}\n",
    "    tv_list = list(unique_series.values())\n",
    "    print(f\"âœ¨ ì¤‘ë³µ ì œê±° ì „: {len(all_tv_series):,}ê°œ â†’ ì¤‘ë³µ ì œê±° í›„: {len(tv_list):,}ê°œ\")\n",
    "    print(f\"   (ì œê±°ëœ ì¤‘ë³µ: {len(all_tv_series) - len(tv_list):,}ê°œ)\")\n",
    "\n",
    "    print(f\"\\n{'='*90}\")\n",
    "    print(\"ğŸ“Œ ìƒì„¸ ì •ë³´ ë©€í‹°ìŠ¤ë ˆë“œ ìˆ˜ì§‘ ì‹œì‘...\\n\")\n",
    "\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=30) as executor:\n",
    "        futures = {executor.submit(fetch_tv_details, s[\"id\"]): s for s in tv_list}\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"TV ìƒì„¸ ìˆ˜ì§‘\"):\n",
    "            detail = future.result()\n",
    "            if detail:\n",
    "                results.append(detail)\n",
    "\n",
    "    print(f\"\\nğŸ‰ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {len(results):,}ê°œ\")\n",
    "\n",
    "    # ì €ì¥\n",
    "    df = pd.DataFrame(results)\n",
    "    df = df.sort_values([\"first_air_date\", \"popularity\"], ascending=[True, False])\n",
    "    df.to_csv(\"tv_series_2023_2025_JanToJun_FULL.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    elapsed = time.time() - total_start\n",
    "\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"========================== DONE ==========================\")\n",
    "    print(f\"ğŸ“Œ ì´ ë°ì´í„°: {len(df):,}ê°œ\")\n",
    "    print(f\"â±  ì†Œìš”ì‹œê°„: {elapsed/60:.2f}ë¶„ ({elapsed:.2f}ì´ˆ)\")\n",
    "    print(f\"ğŸ’¾ ì €ì¥ íŒŒì¼: tv_series_2023_2025_JanToJun_FULL.csv\")\n",
    "    print(f\"\\nğŸš€ ì„±ëŠ¥ ê°œì„  í¬ì¸íŠ¸:\")\n",
    "    print(f\"   âœ… ê¸°ê°„ ë¶„í• ë¡œ 500í˜ì´ì§€ ì œí•œ ìš°íšŒ (ì „ì²´ ë°ì´í„° ìˆ˜ì§‘)\")\n",
    "    print(f\"   âœ… í˜ì´ì§€ ìˆ˜ì§‘ ë©€í‹°ìŠ¤ë ˆë“œí™” (20ê°œ ë™ì‹œ)\")\n",
    "    print(f\"   âœ… ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ìŠ¤ë ˆë“œ ì¦ê°€ (30ê°œ ë™ì‹œ)\")\n",
    "    print(f\"   âœ… HTTP ì—°ê²° í’€ ì¬ì‚¬ìš© (TCP ì—°ê²° ì˜¤ë²„í—¤ë“œ ì œê±°)\")\n",
    "    print(f\"   âœ… ìë™ ì¬ì‹œë„ ë¡œì§ (ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ìë™ ë³µêµ¬)\")\n",
    "    print(\"=\"*90)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
